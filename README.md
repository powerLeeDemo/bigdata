前言
hadoop是分布式系统，运行在linux之上，配置起来相对复杂。对于hadoop1，很多同学就因为不能搭建正确的运行环境，导致学习兴趣锐减。不过，我有免费的学习视频下载，请点击这里。
hadoop2出来后，解决了hadoop1的几个固有缺陷，比如单点故障、资源利用率低、支持作业类型少等问题，结构发生了很大变化，是hadoop未来使用的一个趋势。当然，配置也更加复杂，网上也没有一篇详细的教程来知道大家可以轻轻松松搭建起这个环境的。我应该算是第一个吧。


hadoop2体系结构

要想理解本节内容，首先需要了解hadoop1的体系结构。在本博客中和我的视频中都有相关内容，这里不再重复，只讲hadoop2的内容。
hadoop1的核心组成是两部分，即HDFS和MapReduce。在hadoop2中变为HDFS和Yarn。
新的HDFS中的NameNode不再是只有一个了，可以有多个（目前只支持2个）。每一个都有相同的职能。
这两个NameNode的地位如何哪？答：一个是active状态的，一个是standby状态的。当集群运行时，只有active状态的NameNode是正常工作的，standby状态的NameNode是处于待命状态的，时刻同步active状态NameNode的数据。一旦active状态的NameNode不能工作，通过手工或者自动切换，standby状态的NameNode就可以转变为active状态的，就可以继续工作了。这就是高可靠。
当NameNode发生故障时，他们的数据如何保持一致哪？在这里，2个NameNode的数据其实是实时共享的。新HDFS采用了一种共享机制，JournalNode集群或者NFS进行共享。NFS是操作系统层面的，JournalNode是hadoop层面的，我们这里使用JournalNode集群进行数据共享。
如何实现NameNode的自动切换哪？这就需要使用ZooKeeper集群进行选择了。HDFS集群中的两个NameNode都在ZooKeeper中注册，当active状态的NameNode出故障时，ZooKeeper能检测到这种情况，它就会自动把standby状态的NameNode切换为active状态。
HDFSFederation（HDFS联盟）是怎么回事？答：联盟的出现是有原因的。我们知道NameNode是核心节点，维护着整个HDFS中的元数据信息，那么其容量是有限的，受制于服务器的内存空间。当NameNode服务器的内存装不下数据后，那么HDFS集群就装不下数据了，寿命也就到头了。因此其扩展性是受限的。HDFS联盟指的是有多个HDFS集群同时工作，那么其容量理论上就不受限了，夸张点说就是无限扩展。


配置过程详述

大家从官网下载的apachehadoop2.2.0的代码是32位操作系统下编译的，不能使用64位的jdk。我下面部署的hadoop代码是自己的64位机器上重新编译过的。服务器都是64位的，本配置尽量模拟真实环境。大家可以以32位的操作系统做练习，这是没关系的。关于基本环境的详细配置，大家可以观看我的视频，或者浏览吴超沉思录的相关文章。
在这里我们选用4台机器进行示范，各台机器的职责如下表格所示
	hadoop101	hadoop102	hadoop103	hadoop104
是NameNode吗?	是，属集群c1	是，属集群c1	是，属集群c2	是，属集群c2
是DataNode吗？	是	是	是	是
是JournalNode吗？	是	是	是	不是
是ZooKeeper吗？	是	是	是	不是
是ZKFC吗?	是	是	是	是
配置文件一共包括6个，分别是hadoop-env.sh、core-site.xml、hdfs-site.xml、mapred-site.xml、yarn-site.xml和slaves。除了hdfs-site.xml文件在不同集群配置不同外，其余文件在四个节点的配置是完全一样的，可以复制。

文件hadoop-env.sh

就是修改这一行内容，修改后的结果如下
exportJAVA_HOME=/usr/local/jdk
【这里的JAVA_HOME的值是jdk的安装路径。如果你那里不一样，请修改为自己的地址】


文件core-site.xml
<configuration>
<property>
<name>fs.defaultFS</name>
<value>hdfs://cluster1</value>
</property>
【这里的值指的是默认的HDFS路径。当有多个HDFS集群同时工作时，用户如果不写集群名称，那么默认使用哪个哪？在这里指定！该值来自于hdfs-site.xml中的配置】
<property>
<name>hadoop.tmp.dir</name>
<value>/usr/local/hadoop/tmp</value>
</property>
【这里的路径默认是NameNode、DataNode、JournalNode等存放数据的公共目录。用户也可以自己单独指定这三类节点的目录。】
<property>
<name>ha.zookeeper.quorum</name>
<value>hadoop101:2181,hadoop102:2181,hadoop103:2181</value>
</property>
【这里是ZooKeeper集群的地址和端口。注意，数量一定是奇数，且不少于三个节点】
</configuration>


集群c1的文件hdfs-site.xml
该文件只配置在hadoop101和hadoop102上。
<configuration>
<property>
<name>dfs.replication</name>
<value>2</value>
</property>
【指定DataNode存储block的副本数量。默认值是3个，我们现在有4个DataNode，该值不大于4即可。】
<property>
<name>dfs.nameservices</name>
<value>cluster1,cluster2</value>
</property>
【使用federation时，使用了2个HDFS集群。这里抽象出两个NameService实际上就是给这2个HDFS集群起了个别名。名字可以随便起，相互不重复即可】
<property>
<name>dfs.ha.namenodes.cluster1</name>
<value>hadoop101,hadoop102</value>
</property>
【指定NameService是cluster1时的namenode有哪些，这里的值也是逻辑名称，名字随便起，相互不重复即可】
<property>
<name>dfs.namenode.rpc-address.cluster1.hadoop101</name>
<value>hadoop101:9000</value>
</property>
【指定hadoop101的RPC地址】
<property>
<name>dfs.namenode.http-address.cluster1.hadoop101</name>
<value>hadoop101:50070</value>
</property>
【指定hadoop101的http地址】
<property>
<name>dfs.namenode.rpc-address.cluster1.hadoop102</name>
<value>hadoop102:9000</value>
</property>
【指定hadoop102的RPC地址】
<property>
<name>dfs.namenode.http-address.cluster1.hadoop102</name>
<value>hadoop102:50070</value>
</property>
【指定hadoop102的http地址】
<property>
<name>dfs.namenode.shared.edits.dir</name>
<value>qjournal://hadoop101:8485;hadoop102:8485;hadoop103:8485/cluster1</value>
</property>
【指定cluster1的两个NameNode共享edits文件目录时，使用的JournalNode集群信息】
<property>
<name>dfs.ha.automatic-failover.enabled.cluster1</name>
<value>true</value>
</property>
【指定cluster1是否启动自动故障恢复，即当NameNode出故障时，是否自动切换到另一台NameNode】
<property>
<name>dfs.client.failover.proxy.provider.cluster1</name>
<value>org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider</value>
</property>
【指定cluster1出故障时，哪个实现类负责执行故障切换】
<property>
<name>dfs.ha.namenodes.cluster2</name>
<value>hadoop103,hadoop104</value>
</property>
【指定NameService是cluster2时，两个NameNode是谁，这里是逻辑名称，不重复即可。以下配置与cluster1几乎全部相似，不再添加注释】
<property>
<name>dfs.namenode.rpc-address.cluster2.hadoop103</name>
<value>hadoop103:9000</value>
</property>
<property>
<name>dfs.namenode.http-address.cluster2.hadoop103</name>
<value>hadoop103:50070</value>
</property>
<property>
<name>dfs.namenode.rpc-address.cluster2.hadoop104</name>
<value>hadoop104:9000</value>
</property>
<property>
<name>dfs.namenode.http-address.cluster2.hadoop104</name>
<value>hadoop104:50070</value>
</property>
<!--
<property>
<name>dfs.namenode.shared.edits.dir</name>
<value>qjournal://hadoop101:8485;hadoop102:8485;hadoop103:8485/cluster2</value>
</property>
【这段代码是注释掉的，不要打开】
-->
<property>
<name>dfs.ha.automatic-failover.enabled.cluster2</name>
<value>true</value>
</property>
<property>
<name>dfs.client.failover.proxy.provider.cluster2</name>
<value>org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider</value>
</property>
<property>
<name>dfs.journalnode.edits.dir</name>
<value>/usr/local/hadoop/tmp/journal</value>
</property>
【指定JournalNode集群在对NameNode的目录进行共享时，自己存储数据的磁盘路径】
<property>
<name>dfs.ha.fencing.methods</name>
<value>sshfence</value>
</property>
【一旦需要NameNode切换，使用ssh方式进行操作】
<property>
<name>dfs.ha.fencing.ssh.private-key-files</name>
<value>/root/.ssh/id_rsa</value>
</property>
【如果使用ssh进行故障切换，使用ssh通信时用的密钥存储的位置】
</configuration>


集群c2的文件hdfs-site.xml
该文件只配置在hadoop103和hadoop104上。
该文件与c1中的hdfs-site.xml配置内容完全相同，只有注释位置不一样，一定要注意，不要随便改
<configuration>
<property>
<name>dfs.replication</name>
<value>2</value>
</property>
<property>
<name>dfs.nameservices</name>
<value>cluster1,cluster2</value>
</property>
<property>
<name>dfs.ha.namenodes.cluster1</name>
<value>hadoop101,hadoop102</value>
</property>
<property>
<name>dfs.namenode.rpc-address.cluster1.hadoop101</name>
<value>hadoop101:9000</value>
</property>
<property>
<name>dfs.namenode.http-address.cluster1.hadoop101</name>
<value>hadoop101:50070</value>
</property>
<property>
<name>dfs.namenode.rpc-address.cluster1.hadoop102</name>
<value>hadoop102:9000</value>
</property>
<property>
<name>dfs.namenode.http-address.cluster1.hadoop102</name>
<value>hadoop102:50070</value>
</property>
<!--
<property>
<name>dfs.namenode.shared.edits.dir</name>
<value>qjournal://hadoop101:8485;hadoop102:8485;hadoop103:8485/cluster1</value>
</property>
【这段代码是注释掉的，不要打开】
-->
<property>
<name>dfs.ha.automatic-failover.enabled.cluster1</name>
<value>true</value>
</property>
<property>
<name>dfs.client.failover.proxy.provider.cluster1</name>
<value>org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider</value>
</property>
<property>
<name>dfs.ha.namenodes.cluster2</name>
<value>hadoop103,hadoop104</value>
</property>
<property>
<name>dfs.namenode.rpc-address.cluster2.hadoop103</name>
<value>hadoop103:9000</value>
</property>
<property>
<name>dfs.namenode.http-address.cluster2.hadoop103</name>
<value>hadoop103:50070</value>
</property>
<property>
<name>dfs.namenode.rpc-address.cluster2.hadoop104</name>
<value>hadoop104:9000</value>
</property>
<property>
<name>dfs.namenode.http-address.cluster2.hadoop104</name>
<value>hadoop104:50070</value>
</property>
<property>
<name>dfs.namenode.shared.edits.dir</name>
<value>qjournal://hadoop101:8485;hadoop102:8485;hadoop103:8485/cluster2</value>
</property>
<property>
<name>dfs.ha.automatic-failover.enabled.cluster2</name>
<value>true</value>
</property>
<property>
<name>dfs.client.failover.proxy.provider.cluster2</name>
<value>org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider</value>
</property>
<property>
<name>dfs.journalnode.edits.dir</name>
<value>/usr/local/hadoop/tmp/journal</value>
</property>
<property>
<name>dfs.ha.fencing.methods</name>
<value>sshfence</value>
</property>
<property>
<name>dfs.ha.fencing.ssh.private-key-files</name>
<value>/root/.ssh/id_rsa</value>
</property>
</configuration>

文件mapred-site.xml
<configuration>
<property>
<name>mapreduce.framework.name</name>
<value>yarn</value>
</property>
【指定运行mapreduce的环境是yarn，与hadoop1截然不同的地方】
</configuration>
文件yarn-site.xml
<configuration>
<property>
<name>yarn.resourcemanager.hostname</name>
<value>hadoop101</value>
</property>
【自定ResourceManager的地址，还是单点，这是隐患】
<property>
<name>yarn.nodemanager.aux-services</name>
<value>mapreduce_shuffle</value>
</property>
</configuration>

文件slaves
hadoop101
hadoop102
hadoop103
hadoop104
【指定所有的DataNode节点列表，每行一个节点名称】
注意：以上配置中c1中的hdfs-site.xml文件配置在hadoop101和hadoop102中，c2中的hdfs-site.xml文件配置在hadoop103和hadoop104中。其余文件在各个节点都相同。

启动过程
启动时，要非常小心，请严格按照我这里描述的步骤做，每一步要检查自己的操作是否正确。
1.首先检查各个节点的配置文件是否正确
特别要注意hdfs-site.xml文件，在c1和c2中是不同的。
2.启动ZooKeeper集群
关于ZooKeeper的集群配置和启动描述见吴超沉思录，这里不再详述。
在hadoop101、hadoop102、hadoop103上分别执行命令：zkServer.shstart
命令输出(以hadoop101为例)：
[root@hadoop101hadoop]#zkServer.shstatus
JMXenabledbydefault
Usingconfig:/usr/local/zookeeper/bin/../conf/zoo.cfg
Mode:follower
三个节点都执行完启动命令后，在hadoop101执行以下验证。
验证：
[root@hadoop101hadoop]#zkCli.sh
Connectingtolocalhost:2181
2014-02-1207:20:35,509[myid:]-INFO[main:Environment@100]-Clientenvironment:zookeeper.version=3.4.5-1392090,builton09/30/201217:52GMT
2014-02-1207:20:35,523[myid:]-INFO[main:Environment@100]-Clientenvironment:host.name=hadoop101
2014-02-1207:20:35,524[myid:]-INFO[main:Environment@100]-Clientenvironment:java.version=1.7.0_45
2014-02-1207:20:35,525[myid:]-INFO[main:Environment@100]-Clientenvironment:java.vendor=OracleCorporation
2014-02-1207:20:35,525[myid:]-INFO[main:Environment@100]-Clientenvironment:java.home=/usr/local/jdk/jre
2014-02-1207:20:35,526[myid:]-INFO[main:Environment@100]-Clientenvironment:java.class.path=/usr/local/zookeeper/bin/../build/classes:/usr/local/zookeeper/bin/../build/lib/*.jar:/usr/local/zookeeper/bin/../lib/slf4j-log4j12-1.6.1.jar:/usr/local/zookeeper/bin/../lib/slf4j-api-1.6.1.jar:/usr/local/zookeeper/bin/../lib/netty-3.2.2.Final.jar:/usr/local/zookeeper/bin/../lib/log4j-1.2.15.jar:/usr/local/zookeeper/bin/../lib/jline-0.9.94.jar:/usr/local/zookeeper/bin/../zookeeper-3.4.5.jar:/usr/local/zookeeper/bin/../src/java/lib/*.jar:/usr/local/zookeeper/bin/../conf:/usr/local/hadoop
2014-02-1207:20:35,526[myid:]-INFO[main:Environment@100]-Clientenvironment:java.library.path=/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib
2014-02-1207:20:35,527[myid:]-INFO[main:Environment@100]-Clientenvironment:java.io.tmpdir=/tmp
2014-02-1207:20:35,528[myid:]-INFO[main:Environment@100]-Clientenvironment:java.compiler=<NA>
2014-02-1207:20:35,528[myid:]-INFO[main:Environment@100]-Clientenvironment:os.name=Linux
2014-02-1207:20:35,529[myid:]-INFO[main:Environment@100]-Clientenvironment:os.arch=amd64
2014-02-1207:20:35,529[myid:]-INFO[main:Environment@100]-Clientenvironment:os.version=2.6.32-431.el6.x86_64
2014-02-1207:20:35,530[myid:]-INFO[main:Environment@100]-Clientenvironment:user.name=root
2014-02-1207:20:35,530[myid:]-INFO[main:Environment@100]-Clientenvironment:user.home=/root
2014-02-1207:20:35,531[myid:]-INFO[main:Environment@100]-Clientenvironment:user.dir=/usr/local/hadoop
2014-02-1207:20:35,533[myid:]-INFO[main:ZooKeeper@438]-Initiatingclientconnection,connectString=localhost:2181sessionTimeout=30000watcher=org.apache.zookeeper.ZooKeeperMain$MyWatcher@10636a7e
WelcometoZooKeeper!
2014-02-1207:20:35,569[myid:]-INFO[main-SendThread(127.0.0.1:2181):ClientCnxn$SendThread@966]-Openingsocketconnectiontoserver127.0.0.1/127.0.0.1:2181.WillnotattempttoauthenticateusingSASL(unknownerror)
2014-02-1207:20:35,587[myid:]-INFO[main-SendThread(127.0.0.1:2181):ClientCnxn$SendThread@849]-Socketconnectionestablishedto127.0.0.1/127.0.0.1:2181,initiatingsession
JLinesupportisenabled
2014-02-1207:20:35,687[myid:]-INFO[main-SendThread(127.0.0.1:2181):ClientCnxn$SendThread@1207]-Sessionestablishmentcompleteonserver127.0.0.1/127.0.0.1:2181,sessionid=0x654423404e530000,negotiatedtimeout=30000
WATCHER::
WatchedEventstate:SyncConnectedtype:Nonepath:null
[zk:localhost:2181(CONNECTED)0]ls/
[zookeeper]
[zk:localhost:2181(CONNECTED)1]
【可以看到ZK集群中只有一个节点zookeeper】
3.格式化ZooKeeper集群，目的是在ZooKeeper集群上建立HA的相应节点。
在hadoop101上执行命令：/usr/local/hadoop/bin/hdfszkfc–formatZK
命令输出：
[root@hadoop101hadoop]#/usr/local/hadoop/bin/hdfszkfc-formatZK
14/02/1207:28:56INFOtools.DFSZKFailoverController:FailovercontrollerconfiguredforNameNodeNameNodeathadoop101/192.168.80.101:9000
14/02/1207:28:57INFOzookeeper.ZooKeeper:Clientenvironment:zookeeper.version=3.4.5-1392090,builton09/30/201217:52GMT
14/02/1207:28:57INFOzookeeper.ZooKeeper:Clientenvironment:host.name=hadoop101
14/02/1207:28:57INFOzookeeper.ZooKeeper:Clientenvironment:java.version=1.7.0_45
14/02/1207:28:57INFOzookeeper.ZooKeeper:Clientenvironment:java.vendor=OracleCorporation
14/02/1207:28:57INFOzookeeper.ZooKeeper:Clientenvironment:java.home=/usr/local/jdk/jre
14/02/1207:28:57INFOzookeeper.ZooKeeper:Clientenvironment:java.class.path=/usr/local/hadoop/etc/hadoop:/usr/local/hadoop/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop/share/hadoop/common/lib/jsch-0.1.42.jar:/usr/local/hadoop/share/hadoop/common/lib/jersey-server-1.9.jar:/usr/local/hadoop/share/hadoop/common/lib/slf4j-log4j12-1.7.5.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-digester-1.8.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-cli-1.2.jar:/usr/local/hadoop/share/hadoop/common/lib/jackson-core-asl-1.8.8.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-el-1.0.jar:/usr/local/hadoop/share/hadoop/common/lib/jets3t-0.6.1.jar:/usr/local/hadoop/share/hadoop/common/lib/jersey-core-1.9.jar:/usr/local/hadoop/share/hadoop/common/lib/slf4j-api-1.7.5.jar:/usr/local/hadoop/share/hadoop/common/lib/xz-1.0.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-lang-2.5.jar:/usr/local/hadoop/share/hadoop/common/lib/jasper-runtime-5.5.23.jar:/usr/local/hadoop/share/hadoop/common/lib/jackson-xc-1.8.8.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-codec-1.4.jar:/usr/local/hadoop/share/hadoop/common/lib/activation-1.1.jar:/usr/local/hadoop/share/hadoop/common/lib/avro-1.7.4.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-httpclient-3.1.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/usr/local/hadoop/share/hadoop/common/lib/hadoop-annotations-2.2.0.jar:/usr/local/hadoop/share/hadoop/common/lib/jsp-api-2.1.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-compress-1.4.1.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-configuration-1.6.jar:/usr/local/hadoop/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop/share/hadoop/common/lib/zookeeper-3.4.5.jar:/usr/local/hadoop/share/hadoop/common/lib/hadoop-auth-2.2.0.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-io-2.1.jar:/usr/local/hadoop/share/hadoop/common/lib/netty-3.6.2.Final.jar:/usr/local/hadoop/share/hadoop/common/lib/stax-api-1.0.1.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-collections-3.2.1.jar:/usr/local/hadoop/share/hadoop/common/lib/servlet-api-2.5.jar:/usr/local/hadoop/share/hadoop/common/lib/junit-4.8.2.jar:/usr/local/hadoop/share/hadoop/common/lib/jetty-util-6.1.26.jar:/usr/local/hadoop/share/hadoop/common/lib/jackson-mapper-asl-1.8.8.jar:/usr/local/hadoop/share/hadoop/common/lib/jsr305-1.3.9.jar:/usr/local/hadoop/share/hadoop/common/lib/mockito-all-1.8.5.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-logging-1.1.1.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-math-2.1.jar:/usr/local/hadoop/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop/share/hadoop/common/lib/jersey-json-1.9.jar:/usr/local/hadoop/share/hadoop/common/lib/asm-3.2.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-net-3.1.jar:/usr/local/hadoop/share/hadoop/common/lib/jetty-6.1.26.jar:/usr/local/hadoop/share/hadoop/common/lib/jasper-compiler-5.5.23.jar:/usr/local/hadoop/share/hadoop/common/lib/guava-11.0.2.jar:/usr/local/hadoop/share/hadoop/common/lib/xmlenc-0.52.jar:/usr/local/hadoop/share/hadoop/common/lib/log4j-1.2.17.jar:/usr/local/hadoop/share/hadoop/common/lib/paranamer-2.3.jar:/usr/local/hadoop/share/hadoop/common/lib/jackson-jaxrs-1.8.8.jar:/usr/local/hadoop/share/hadoop/common/lib/jettison-1.1.jar:/usr/local/hadoop/share/hadoop/common/hadoop-common-2.2.0-tests.jar:/usr/local/hadoop/share/hadoop/common/hadoop-common-2.2.0.jar:/usr/local/hadoop/share/hadoop/common/hadoop-nfs-2.2.0.jar:/usr/local/hadoop/share/hadoop/hdfs:/usr/local/hadoop/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jackson-core-asl-1.8.8.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-el-1.0.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-lang-2.5.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jasper-runtime-5.5.23.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jsp-api-2.1.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-io-2.1.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jackson-mapper-asl-1.8.8.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jsr305-1.3.9.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-logging-1.1.1.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/asm-3.2.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/guava-11.0.2.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/usr/local/hadoop/share/hadoop/hdfs/hadoop-hdfs-nfs-2.2.0.jar:/usr/local/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.2.0-tests.jar:/usr/local/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.2.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jersey-server-1.9.jar:/usr/local/hadoop/share/hadoop/yarn/lib/guice-3.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jackson-core-asl-1.8.8.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jersey-core-1.9.jar:/usr/local/hadoop/share/hadoop/yarn/lib/xz-1.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/hamcrest-core-1.1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/avro-1.7.4.jar:/usr/local/hadoop/share/hadoop/yarn/lib/aopalliance-1.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/hadoop-annotations-2.2.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/javax.inject-1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-io-2.1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jackson-mapper-asl-1.8.8.jar:/usr/local/hadoop/share/hadoop/yarn/lib/asm-3.2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/junit-4.10.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/usr/local/hadoop/share/hadoop/yarn/lib/log4j-1.2.17.jar:/usr/local/hadoop/share/hadoop/yarn/lib/paranamer-2.3.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-api-2.2.0.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-tests-2.2.0.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-site-2.2.0.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-client-2.2.0.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.2.0.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.2.0.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.2.0.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.2.0.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.2.0.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-common-2.2.0.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-common-2.2.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/guice-3.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/jackson-core-asl-1.8.8.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/xz-1.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/hamcrest-core-1.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/hadoop-annotations-2.2.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/javax.inject-1.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/commons-io-2.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.8.8.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/asm-3.2.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/junit-4.10.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.2.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.2.0-tests.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.2.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.2.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.2.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.2.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.2.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.2.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.2.0.jar:/usr/local/hadoop/contrib/capacity-scheduler/*.jar
14/02/1207:28:57INFOzookeeper.ZooKeeper:Clientenvironment:java.library.path=/usr/local/hadoop/lib/native
14/02/1207:28:57INFOzookeeper.ZooKeeper:Clientenvironment:java.io.tmpdir=/tmp
14/02/1207:28:57INFOzookeeper.ZooKeeper:Clientenvironment:java.compiler=<NA>
14/02/1207:28:57INFOzookeeper.ZooKeeper:Clientenvironment:os.name=Linux
14/02/1207:28:57INFOzookeeper.ZooKeeper:Clientenvironment:os.arch=amd64
14/02/1207:28:57INFOzookeeper.ZooKeeper:Clientenvironment:os.version=2.6.32-431.el6.x86_64
14/02/1207:28:57INFOzookeeper.ZooKeeper:Clientenvironment:user.name=root
14/02/1207:28:57INFOzookeeper.ZooKeeper:Clientenvironment:user.home=/root
14/02/1207:28:57INFOzookeeper.ZooKeeper:Clientenvironment:user.dir=/usr/local/hadoop
14/02/1207:28:57INFOzookeeper.ZooKeeper:Initiatingclientconnection,connectString=hadoop101:2181,hadoop102:2181,hadoop103:2181sessionTimeout=5000watcher=org.apache.hadoop.ha.ActiveStandbyElector$WatcherWithClientRef@3e9c00ea
14/02/1207:28:57INFOzookeeper.ClientCnxn:Openingsocketconnectiontoserverhadoop102/192.168.80.102:2181.WillnotattempttoauthenticateusingSASL(unknownerror)
14/02/1207:28:57INFOzookeeper.ClientCnxn:Socketconnectionestablishedtohadoop102/192.168.80.102:2181,initiatingsession
14/02/1207:28:57INFOzookeeper.ClientCnxn:Sessionestablishmentcompleteonserverhadoop102/192.168.80.102:2181,sessionid=0x6644234039710000,negotiatedtimeout=5000
14/02/1207:28:57INFOha.ActiveStandbyElector:Sessionconnected.
14/02/1207:28:57INFOha.ActiveStandbyElector:Successfullycreated/hadoop-ha/cluster1inZK.
14/02/1207:28:57INFOzookeeper.ZooKeeper:Session:0x6644234039710000closed
14/02/1207:28:57INFOzookeeper.ClientCnxn:EventThreadshutdown
[root@hadoop101hadoop]#
验证：
[root@hadoop101hadoop]#zkCli.sh
Connectingtolocalhost:2181
2014-02-1207:30:24,355[myid:]-INFO[main:Environment@100]-Clientenvironment:zookeeper.version=3.4.5-1392090,builton09/30/201217:52GMT
2014-02-1207:30:24,373[myid:]-INFO[main:Environment@100]-Clientenvironment:host.name=hadoop101
2014-02-1207:30:24,374[myid:]-INFO[main:Environment@100]-Clientenvironment:java.version=1.7.0_45
2014-02-1207:30:24,375[myid:]-INFO[main:Environment@100]-Clientenvironment:java.vendor=OracleCorporation
2014-02-1207:30:24,376[myid:]-INFO[main:Environment@100]-Clientenvironment:java.home=/usr/local/jdk/jre
2014-02-1207:30:24,376[myid:]-INFO[main:Environment@100]-Clientenvironment:java.class.path=/usr/local/zookeeper/bin/../build/classes:/usr/local/zookeeper/bin/../build/lib/*.jar:/usr/local/zookeeper/bin/../lib/slf4j-log4j12-1.6.1.jar:/usr/local/zookeeper/bin/../lib/slf4j-api-1.6.1.jar:/usr/local/zookeeper/bin/../lib/netty-3.2.2.Final.jar:/usr/local/zookeeper/bin/../lib/log4j-1.2.15.jar:/usr/local/zookeeper/bin/../lib/jline-0.9.94.jar:/usr/local/zookeeper/bin/../zookeeper-3.4.5.jar:/usr/local/zookeeper/bin/../src/java/lib/*.jar:/usr/local/zookeeper/bin/../conf:/usr/local/hadoop
2014-02-1207:30:24,378[myid:]-INFO[main:Environment@100]-Clientenvironment:java.library.path=/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib
2014-02-1207:30:24,379[myid:]-INFO[main:Environment@100]-Clientenvironment:java.io.tmpdir=/tmp
2014-02-1207:30:24,380[myid:]-INFO[main:Environment@100]-Clientenvironment:java.compiler=<NA>
2014-02-1207:30:24,381[myid:]-INFO[main:Environment@100]-Clientenvironment:os.name=Linux
2014-02-1207:30:24,382[myid:]-INFO[main:Environment@100]-Clientenvironment:os.arch=amd64
2014-02-1207:30:24,382[myid:]-INFO[main:Environment@100]-Clientenvironment:os.version=2.6.32-431.el6.x86_64
2014-02-1207:30:24,383[myid:]-INFO[main:Environment@100]-Clientenvironment:user.name=root
2014-02-1207:30:24,383[myid:]-INFO[main:Environment@100]-Clientenvironment:user.home=/root
2014-02-1207:30:24,384[myid:]-INFO[main:Environment@100]-Clientenvironment:user.dir=/usr/local/hadoop
2014-02-1207:30:24,387[myid:]-INFO[main:ZooKeeper@438]-Initiatingclientconnection,connectString=localhost:2181sessionTimeout=30000watcher=org.apache.zookeeper.ZooKeeperMain$MyWatcher@10636a7e
WelcometoZooKeeper!
2014-02-1207:30:24,422[myid:]-INFO[main-SendThread(127.0.0.1:2181):ClientCnxn$SendThread@966]-Openingsocketconnectiontoserver127.0.0.1/127.0.0.1:2181.WillnotattempttoauthenticateusingSASL(unknownerror)
2014-02-1207:30:24,462[myid:]-INFO[main-SendThread(127.0.0.1:2181):ClientCnxn$SendThread@849]-Socketconnectionestablishedto127.0.0.1/127.0.0.1:2181,initiatingsession
JLinesupportisenabled
2014-02-1207:30:24,494[myid:]-INFO[main-SendThread(127.0.0.1:2181):ClientCnxn$SendThread@1207]-Sessionestablishmentcompleteonserver127.0.0.1/127.0.0.1:2181,sessionid=0x654423404e530001,negotiatedtimeout=30000
WATCHER::
WatchedEventstate:SyncConnectedtype:Nonepath:null
[zk:localhost:2181(CONNECTED)0]ls/
[hadoop-ha,zookeeper]
[zk:localhost:2181(CONNECTED)1]ls/hadoop-ha
[cluster1]
[zk:localhost:2181(CONNECTED)2]
【格式化操作的目的是在ZK集群中建立一个节点，用于保存集群c1中NameNode的状态数据】
在hadoop103上执行命令：/usr/local/hadoop/bin/hdfszkfc–formatZK
命令输出：
[root@hadoop103hadoop]#/usr/local/hadoop/bin/hdfszkfc-formatZK
14/02/1207:32:14WARNutil.NativeCodeLoader:Unabletoloadnative-hadooplibraryforyourplatform...usingbuiltin-javaclasseswhereapplicable
14/02/1207:32:14INFOtools.DFSZKFailoverController:FailovercontrollerconfiguredforNameNodeNameNodeathadoop103/192.168.80.103:9000
14/02/1207:32:14INFOzookeeper.ZooKeeper:Clientenvironment:zookeeper.version=3.4.5-1392090,builton09/30/201217:52GMT
14/02/1207:32:14INFOzookeeper.ZooKeeper:Clientenvironment:host.name=hadoop103
14/02/1207:32:14INFOzookeeper.ZooKeeper:Clientenvironment:java.version=1.7.0_45
14/02/1207:32:14INFOzookeeper.ZooKeeper:Clientenvironment:java.vendor=OracleCorporation
14/02/1207:32:14INFOzookeeper.ZooKeeper:Clientenvironment:java.home=/usr/local/jdk/jre
14/02/1207:32:14INFOzookeeper.ZooKeeper:Clientenvironment:java.class.path=/usr/local/hadoop/etc/hadoop:/usr/local/hadoop/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop/share/hadoop/common/lib/jsch-0.1.42.jar:/usr/local/hadoop/share/hadoop/common/lib/jersey-server-1.9.jar:/usr/local/hadoop/share/hadoop/common/lib/slf4j-log4j12-1.7.5.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-digester-1.8.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-cli-1.2.jar:/usr/local/hadoop/share/hadoop/common/lib/jackson-core-asl-1.8.8.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-el-1.0.jar:/usr/local/hadoop/share/hadoop/common/lib/jets3t-0.6.1.jar:/usr/local/hadoop/share/hadoop/common/lib/jersey-core-1.9.jar:/usr/local/hadoop/share/hadoop/common/lib/slf4j-api-1.7.5.jar:/usr/local/hadoop/share/hadoop/common/lib/xz-1.0.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-lang-2.5.jar:/usr/local/hadoop/share/hadoop/common/lib/jasper-runtime-5.5.23.jar:/usr/local/hadoop/share/hadoop/common/lib/jackson-xc-1.8.8.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-codec-1.4.jar:/usr/local/hadoop/share/hadoop/common/lib/activation-1.1.jar:/usr/local/hadoop/share/hadoop/common/lib/avro-1.7.4.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-httpclient-3.1.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/usr/local/hadoop/share/hadoop/common/lib/hadoop-annotations-2.2.0.jar:/usr/local/hadoop/share/hadoop/common/lib/jsp-api-2.1.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-compress-1.4.1.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-configuration-1.6.jar:/usr/local/hadoop/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop/share/hadoop/common/lib/zookeeper-3.4.5.jar:/usr/local/hadoop/share/hadoop/common/lib/hadoop-auth-2.2.0.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-io-2.1.jar:/usr/local/hadoop/share/hadoop/common/lib/netty-3.6.2.Final.jar:/usr/local/hadoop/share/hadoop/common/lib/stax-api-1.0.1.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-collections-3.2.1.jar:/usr/local/hadoop/share/hadoop/common/lib/servlet-api-2.5.jar:/usr/local/hadoop/share/hadoop/common/lib/junit-4.8.2.jar:/usr/local/hadoop/share/hadoop/common/lib/jetty-util-6.1.26.jar:/usr/local/hadoop/share/hadoop/common/lib/jackson-mapper-asl-1.8.8.jar:/usr/local/hadoop/share/hadoop/common/lib/jsr305-1.3.9.jar:/usr/local/hadoop/share/hadoop/common/lib/mockito-all-1.8.5.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-logging-1.1.1.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-math-2.1.jar:/usr/local/hadoop/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop/share/hadoop/common/lib/jersey-json-1.9.jar:/usr/local/hadoop/share/hadoop/common/lib/asm-3.2.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-net-3.1.jar:/usr/local/hadoop/share/hadoop/common/lib/jetty-6.1.26.jar:/usr/local/hadoop/share/hadoop/common/lib/jasper-compiler-5.5.23.jar:/usr/local/hadoop/share/hadoop/common/lib/guava-11.0.2.jar:/usr/local/hadoop/share/hadoop/common/lib/xmlenc-0.52.jar:/usr/local/hadoop/share/hadoop/common/lib/log4j-1.2.17.jar:/usr/local/hadoop/share/hadoop/common/lib/paranamer-2.3.jar:/usr/local/hadoop/share/hadoop/common/lib/jackson-jaxrs-1.8.8.jar:/usr/local/hadoop/share/hadoop/common/lib/jettison-1.1.jar:/usr/local/hadoop/share/hadoop/common/hadoop-common-2.2.0-tests.jar:/usr/local/hadoop/share/hadoop/common/hadoop-common-2.2.0.jar:/usr/local/hadoop/share/hadoop/common/hadoop-nfs-2.2.0.jar:/usr/local/hadoop/share/hadoop/hdfs:/usr/local/hadoop/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jackson-core-asl-1.8.8.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-el-1.0.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-lang-2.5.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jasper-runtime-5.5.23.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jsp-api-2.1.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-io-2.1.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jackson-mapper-asl-1.8.8.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jsr305-1.3.9.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-logging-1.1.1.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/asm-3.2.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/guava-11.0.2.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/usr/local/hadoop/share/hadoop/hdfs/hadoop-hdfs-nfs-2.2.0.jar:/usr/local/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.2.0-tests.jar:/usr/local/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.2.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jersey-server-1.9.jar:/usr/local/hadoop/share/hadoop/yarn/lib/guice-3.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jackson-core-asl-1.8.8.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jersey-core-1.9.jar:/usr/local/hadoop/share/hadoop/yarn/lib/xz-1.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/hamcrest-core-1.1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/avro-1.7.4.jar:/usr/local/hadoop/share/hadoop/yarn/lib/aopalliance-1.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/hadoop-annotations-2.2.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/javax.inject-1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-io-2.1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jackson-mapper-asl-1.8.8.jar:/usr/local/hadoop/share/hadoop/yarn/lib/asm-3.2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/junit-4.10.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/usr/local/hadoop/share/hadoop/yarn/lib/log4j-1.2.17.jar:/usr/local/hadoop/share/hadoop/yarn/lib/paranamer-2.3.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-api-2.2.0.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-tests-2.2.0.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-site-2.2.0.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-client-2.2.0.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.2.0.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.2.0.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.2.0.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.2.0.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.2.0.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-common-2.2.0.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-common-2.2.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/guice-3.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/jackson-core-asl-1.8.8.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/xz-1.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/hamcrest-core-1.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/hadoop-annotations-2.2.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/javax.inject-1.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/commons-io-2.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.8.8.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/asm-3.2.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/junit-4.10.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.2.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.2.0-tests.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.2.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.2.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.2.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.2.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.2.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.2.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.2.0.jar:/usr/local/hadoop/contrib/capacity-scheduler/*.jar
14/02/1207:32:14INFOzookeeper.ZooKeeper:Clientenvironment:java.library.path=/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib
14/02/1207:32:14INFOzookeeper.ZooKeeper:Clientenvironment:java.io.tmpdir=/tmp
14/02/1207:32:14INFOzookeeper.ZooKeeper:Clientenvironment:java.compiler=<NA>
14/02/1207:32:14INFOzookeeper.ZooKeeper:Clientenvironment:os.name=Linux
14/02/1207:32:14INFOzookeeper.ZooKeeper:Clientenvironment:os.arch=amd64
14/02/1207:32:14INFOzookeeper.ZooKeeper:Clientenvironment:os.version=2.6.32-431.el6.x86_64
14/02/1207:32:14INFOzookeeper.ZooKeeper:Clientenvironment:user.name=root
14/02/1207:32:14INFOzookeeper.ZooKeeper:Clientenvironment:user.home=/root
14/02/1207:32:14INFOzookeeper.ZooKeeper:Clientenvironment:user.dir=/usr/local/hadoop
14/02/1207:32:14INFOzookeeper.ZooKeeper:Initiatingclientconnection,connectString=hadoop101:2181,hadoop102:2181,hadoop103:2181sessionTimeout=5000watcher=org.apache.hadoop.ha.ActiveStandbyElector$WatcherWithClientRef@91d3b18
14/02/1207:32:14INFOzookeeper.ClientCnxn:Openingsocketconnectiontoserverhadoop102/192.168.80.102:2181.WillnotattempttoauthenticateusingSASL(unknownerror)
14/02/1207:32:14INFOzookeeper.ClientCnxn:Socketconnectionestablishedtohadoop102/192.168.80.102:2181,initiatingsession
14/02/1207:32:14INFOzookeeper.ClientCnxn:Sessionestablishmentcompleteonserverhadoop102/192.168.80.102:2181,sessionid=0x6644234039710001,negotiatedtimeout=5000
14/02/1207:32:14INFOha.ActiveStandbyElector:Sessionconnected.
14/02/1207:32:14INFOha.ActiveStandbyElector:Successfullycreated/hadoop-ha/cluster2inZK.
14/02/1207:32:14INFOzookeeper.ZooKeeper:Session:0x6644234039710001closed
14/02/1207:32:14INFOzookeeper.ClientCnxn:EventThreadshutdown
验证：
[root@hadoop103hadoop]#zkCli.sh
Connectingtolocalhost:2181
2014-02-1207:32:21,770[myid:]-INFO[main:Environment@100]-Clientenvironment:zookeeper.version=3.4.5-1392090,builton09/30/201217:52GMT
2014-02-1207:32:21,786[myid:]-INFO[main:Environment@100]-Clientenvironment:host.name=hadoop103
2014-02-1207:32:21,788[myid:]-INFO[main:Environment@100]-Clientenvironment:java.version=1.7.0_45
2014-02-1207:32:21,789[myid:]-INFO[main:Environment@100]-Clientenvironment:java.vendor=OracleCorporation
2014-02-1207:32:21,789[myid:]-INFO[main:Environment@100]-Clientenvironment:java.home=/usr/local/jdk/jre
2014-02-1207:32:21,790[myid:]-INFO[main:Environment@100]-Clientenvironment:java.class.path=/usr/local/zookeeper/bin/../build/classes:/usr/local/zookeeper/bin/../build/lib/*.jar:/usr/local/zookeeper/bin/../lib/slf4j-log4j12-1.6.1.jar:/usr/local/zookeeper/bin/../lib/slf4j-api-1.6.1.jar:/usr/local/zookeeper/bin/../lib/netty-3.2.2.Final.jar:/usr/local/zookeeper/bin/../lib/log4j-1.2.15.jar:/usr/local/zookeeper/bin/../lib/jline-0.9.94.jar:/usr/local/zookeeper/bin/../zookeeper-3.4.5.jar:/usr/local/zookeeper/bin/../src/java/lib/*.jar:/usr/local/zookeeper/bin/../conf:/usr/local/hadoop
2014-02-1207:32:21,791[myid:]-INFO[main:Environment@100]-Clientenvironment:java.library.path=/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib
2014-02-1207:32:21,792[myid:]-INFO[main:Environment@100]-Clientenvironment:java.io.tmpdir=/tmp
2014-02-1207:32:21,793[myid:]-INFO[main:Environment@100]-Clientenvironment:java.compiler=<NA>
2014-02-1207:32:21,793[myid:]-INFO[main:Environment@100]-Clientenvironment:os.name=Linux
2014-02-1207:32:21,794[myid:]-INFO[main:Environment@100]-Clientenvironment:os.arch=amd64
2014-02-1207:32:21,794[myid:]-INFO[main:Environment@100]-Clientenvironment:os.version=2.6.32-431.el6.x86_64
2014-02-1207:32:21,795[myid:]-INFO[main:Environment@100]-Clientenvironment:user.name=root
2014-02-1207:32:21,796[myid:]-INFO[main:Environment@100]-Clientenvironment:user.home=/root
2014-02-1207:32:21,796[myid:]-INFO[main:Environment@100]-Clientenvironment:user.dir=/usr/local/hadoop
2014-02-1207:32:21,801[myid:]-INFO[main:ZooKeeper@438]-Initiatingclientconnection,connectString=localhost:2181sessionTimeout=30000watcher=org.apache.zookeeper.ZooKeeperMain$MyWatcher@10636a7e
WelcometoZooKeeper!
2014-02-1207:32:21,850[myid:]-INFO[main-SendThread(127.0.0.1:2181):ClientCnxn$SendThread@966]-Openingsocketconnectiontoserver127.0.0.1/127.0.0.1:2181.WillnotattempttoauthenticateusingSASL(unknownerror)
JLinesupportisenabled
2014-02-1207:32:21,868[myid:]-INFO[main-SendThread(127.0.0.1:2181):ClientCnxn$SendThread@849]-Socketconnectionestablishedto127.0.0.1/127.0.0.1:2181,initiatingsession
2014-02-1207:32:21,906[myid:]-INFO[main-SendThread(127.0.0.1:2181):ClientCnxn$SendThread@1207]-Sessionestablishmentcompleteonserver127.0.0.1/127.0.0.1:2181,sessionid=0x6744234039810002,negotiatedtimeout=30000
WATCHER::
WatchedEventstate:SyncConnectedtype:Nonepath:null
[zk:localhost:2181(CONNECTED)0]ls/
[hadoop-ha,zookeeper]
[zk:localhost:2181(CONNECTED)1]ls/hadoop-ha
[cluster2,cluster1]
[zk:localhost:2181(CONNECTED)2]
【集群c2也格式化，产生一个新的ZK节点cluster2】
4.启动JournalNode集群
在hadoop101、hadoop102、hadoop103上分别执行命令：/usr/local/hadoop/sbin/hadoop-daemon.shstartjournalnode
命令输出(以hadoop101为例)：
[root@hadoop101hadoop]#/usr/local/hadoop/sbin/hadoop-daemon.shstartjournalnode
startingjournalnode,loggingto/usr/local/hadoop/logs/hadoop-root-journalnode-hadoop101.out
[root@hadoop101hadoop]#
在每个节点执行完启动命令后，每个节点都执行以下验证。
验证(以hadoop101为例)：

[root@hadoop101hadoop]#jps
23396JournalNode
23598Jps
22491QuorumPeerMain
[root@hadoop101hadoop]#
【产生一个java进程JournalNode】
查看一下目录结构
[root@hadoop101hadoop]#jps
23396JournalNode
22491QuorumPeerMain
23445Jps
[root@hadoop101hadoop]#pwd
/usr/local/hadoop
[root@hadoop101hadoop]#lstmp/
journal
[root@hadoop101hadoop]#
【启动JournalNode后，会在本地磁盘产生一个目录，用户保存NameNode的edits文件的数据】
5.格式化集群c1的一个NameNode
从hadoop101和hadoop102中任选一个即可，这里选择的是hadoop101
在hadoop101执行以下命令：/usr/local/hadoop/bin/hdfsnamenode-format-clusterIdc1
命令输出：
[root@hadoop101hadoop]#/usr/local/hadoop/bin/hdfsnamenode-format-clusterIdc1
14/02/1208:07:59INFOnamenode.NameNode:STARTUP_MSG:
/************************************************************
STARTUP_MSG:StartingNameNode
STARTUP_MSG:host=hadoop101/192.168.80.101
STARTUP_MSG:args=[-format,-clusterId,c1]
STARTUP_MSG:version=2.2.0
STARTUP_MSG:classpath=/usr/local/hadoop/etc/hadoop:/usr/local/hadoop/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop/share/hadoop/common/lib/jsch-0.1.42.jar:/usr/local/hadoop/share/hadoop/common/lib/jersey-server-1.9.jar:/usr/local/hadoop/share/hadoop/common/lib/slf4j-log4j12-1.7.5.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-digester-1.8.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-cli-1.2.jar:/usr/local/hadoop/share/hadoop/common/lib/jackson-core-asl-1.8.8.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-el-1.0.jar:/usr/local/hadoop/share/hadoop/common/lib/jets3t-0.6.1.jar:/usr/local/hadoop/share/hadoop/common/lib/jersey-core-1.9.jar:/usr/local/hadoop/share/hadoop/common/lib/slf4j-api-1.7.5.jar:/usr/local/hadoop/share/hadoop/common/lib/xz-1.0.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-lang-2.5.jar:/usr/local/hadoop/share/hadoop/common/lib/jasper-runtime-5.5.23.jar:/usr/local/hadoop/share/hadoop/common/lib/jackson-xc-1.8.8.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-codec-1.4.jar:/usr/local/hadoop/share/hadoop/common/lib/activation-1.1.jar:/usr/local/hadoop/share/hadoop/common/lib/avro-1.7.4.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-httpclient-3.1.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/usr/local/hadoop/share/hadoop/common/lib/hadoop-annotations-2.2.0.jar:/usr/local/hadoop/share/hadoop/common/lib/jsp-api-2.1.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-compress-1.4.1.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-configuration-1.6.jar:/usr/local/hadoop/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop/share/hadoop/common/lib/zookeeper-3.4.5.jar:/usr/local/hadoop/share/hadoop/common/lib/hadoop-auth-2.2.0.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-io-2.1.jar:/usr/local/hadoop/share/hadoop/common/lib/netty-3.6.2.Final.jar:/usr/local/hadoop/share/hadoop/common/lib/stax-api-1.0.1.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-collections-3.2.1.jar:/usr/local/hadoop/share/hadoop/common/lib/servlet-api-2.5.jar:/usr/local/hadoop/share/hadoop/common/lib/junit-4.8.2.jar:/usr/local/hadoop/share/hadoop/common/lib/jetty-util-6.1.26.jar:/usr/local/hadoop/share/hadoop/common/lib/jackson-mapper-asl-1.8.8.jar:/usr/local/hadoop/share/hadoop/common/lib/jsr305-1.3.9.jar:/usr/local/hadoop/share/hadoop/common/lib/mockito-all-1.8.5.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-logging-1.1.1.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-math-2.1.jar:/usr/local/hadoop/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop/share/hadoop/common/lib/jersey-json-1.9.jar:/usr/local/hadoop/share/hadoop/common/lib/asm-3.2.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-net-3.1.jar:/usr/local/hadoop/share/hadoop/common/lib/jetty-6.1.26.jar:/usr/local/hadoop/share/hadoop/common/lib/jasper-compiler-5.5.23.jar:/usr/local/hadoop/share/hadoop/common/lib/guava-11.0.2.jar:/usr/local/hadoop/share/hadoop/common/lib/xmlenc-0.52.jar:/usr/local/hadoop/share/hadoop/common/lib/log4j-1.2.17.jar:/usr/local/hadoop/share/hadoop/common/lib/paranamer-2.3.jar:/usr/local/hadoop/share/hadoop/common/lib/jackson-jaxrs-1.8.8.jar:/usr/local/hadoop/share/hadoop/common/lib/jettison-1.1.jar:/usr/local/hadoop/share/hadoop/common/hadoop-common-2.2.0-tests.jar:/usr/local/hadoop/share/hadoop/common/hadoop-common-2.2.0.jar:/usr/local/hadoop/share/hadoop/common/hadoop-nfs-2.2.0.jar:/usr/local/hadoop/share/hadoop/hdfs:/usr/local/hadoop/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jackson-core-asl-1.8.8.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-el-1.0.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-lang-2.5.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jasper-runtime-5.5.23.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jsp-api-2.1.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-io-2.1.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jackson-mapper-asl-1.8.8.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jsr305-1.3.9.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-logging-1.1.1.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/asm-3.2.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/guava-11.0.2.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/usr/local/hadoop/share/hadoop/hdfs/hadoop-hdfs-nfs-2.2.0.jar:/usr/local/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.2.0-tests.jar:/usr/local/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.2.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jersey-server-1.9.jar:/usr/local/hadoop/share/hadoop/yarn/lib/guice-3.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jackson-core-asl-1.8.8.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jersey-core-1.9.jar:/usr/local/hadoop/share/hadoop/yarn/lib/xz-1.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/hamcrest-core-1.1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/avro-1.7.4.jar:/usr/local/hadoop/share/hadoop/yarn/lib/aopalliance-1.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/hadoop-annotations-2.2.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/javax.inject-1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-io-2.1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jackson-mapper-asl-1.8.8.jar:/usr/local/hadoop/share/hadoop/yarn/lib/asm-3.2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/junit-4.10.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/usr/local/hadoop/share/hadoop/yarn/lib/log4j-1.2.17.jar:/usr/local/hadoop/share/hadoop/yarn/lib/paranamer-2.3.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-api-2.2.0.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-tests-2.2.0.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-site-2.2.0.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-client-2.2.0.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.2.0.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.2.0.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.2.0.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.2.0.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.2.0.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-common-2.2.0.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-common-2.2.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/guice-3.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/jackson-core-asl-1.8.8.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/xz-1.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/hamcrest-core-1.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/hadoop-annotations-2.2.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/javax.inject-1.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/commons-io-2.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.8.8.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/asm-3.2.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/junit-4.10.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.2.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.2.0-tests.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.2.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.2.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.2.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.2.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.2.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.2.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.2.0.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:build=Unknown-rUnknown;compiledby'root'on2013-12-26T08:50Z
STARTUP_MSG:java=1.7.0_45
************************************************************/
14/02/1208:07:59INFOnamenode.NameNode:registeredUNIXsignalhandlersfor[TERM,HUP,INT]
Formattingusingclusterid:c1
14/02/1208:08:01INFOnamenode.HostFileManager:readincludes:
HostSet(
)
14/02/1208:08:01INFOnamenode.HostFileManager:readexcludes:
HostSet(
)
14/02/1208:08:01INFOblockmanagement.DatanodeManager:dfs.block.invalidate.limit=1000
14/02/1208:08:01INFOutil.GSet:ComputingcapacityformapBlocksMap
14/02/1208:08:01INFOutil.GSet:VMtype=64-bit
14/02/1208:08:01INFOutil.GSet:2.0%maxmemory=966.7MB
14/02/1208:08:01INFOutil.GSet:capacity=2^21=2097152entries
14/02/1208:08:01INFOblockmanagement.BlockManager:dfs.block.access.token.enable=false
14/02/1208:08:01INFOblockmanagement.BlockManager:defaultReplication=2
14/02/1208:08:01INFOblockmanagement.BlockManager:maxReplication=512
14/02/1208:08:01INFOblockmanagement.BlockManager:minReplication=1
14/02/1208:08:01INFOblockmanagement.BlockManager:maxReplicationStreams=2
14/02/1208:08:01INFOblockmanagement.BlockManager:shouldCheckForEnoughRacks=false
14/02/1208:08:01INFOblockmanagement.BlockManager:replicationRecheckInterval=3000
14/02/1208:08:01INFOblockmanagement.BlockManager:encryptDataTransfer=false
14/02/1208:08:01INFOnamenode.FSNamesystem:fsOwner=root(auth:SIMPLE)
14/02/1208:08:01INFOnamenode.FSNamesystem:supergroup=supergroup
14/02/1208:08:01INFOnamenode.FSNamesystem:isPermissionEnabled=true
14/02/1208:08:01INFOnamenode.FSNamesystem:DeterminednameserviceID:cluster1
14/02/1208:08:01INFOnamenode.FSNamesystem:HAEnabled:true
14/02/1208:08:01INFOnamenode.FSNamesystem:AppendEnabled:true
14/02/1208:08:01INFOutil.GSet:ComputingcapacityformapINodeMap
14/02/1208:08:01INFOutil.GSet:VMtype=64-bit
14/02/1208:08:01INFOutil.GSet:1.0%maxmemory=966.7MB
14/02/1208:08:01INFOutil.GSet:capacity=2^20=1048576entries
14/02/1208:08:01INFOnamenode.NameNode:Cachingfilenamesoccuringmorethan10times
14/02/1208:08:01INFOnamenode.FSNamesystem:dfs.namenode.safemode.threshold-pct=0.9990000128746033
14/02/1208:08:01INFOnamenode.FSNamesystem:dfs.namenode.safemode.min.datanodes=0
14/02/1208:08:01INFOnamenode.FSNamesystem:dfs.namenode.safemode.extension=30000
14/02/1208:08:01INFOnamenode.FSNamesystem:Retrycacheonnamenodeisenabled
14/02/1208:08:01INFOnamenode.FSNamesystem:Retrycachewilluse0.03oftotalheapandretrycacheentryexpirytimeis600000millis
14/02/1208:08:01INFOutil.GSet:ComputingcapacityformapNamenodeRetryCache
14/02/1208:08:01INFOutil.GSet:VMtype=64-bit
14/02/1208:08:01INFOutil.GSet:0.029999999329447746%maxmemory=966.7MB
14/02/1208:08:01INFOutil.GSet:capacity=2^15=32768entries
14/02/1208:08:03INFOcommon.Storage:Storagedirectory/usr/local/hadoop/tmp/dfs/namehasbeensuccessfullyformatted.
14/02/1208:08:04INFOnamenode.FSImage:Savingimagefile/usr/local/hadoop/tmp/dfs/name/current/fsimage.ckpt_0000000000000000000usingnocompression
14/02/1208:08:04INFOnamenode.FSImage:Imagefile/usr/local/hadoop/tmp/dfs/name/current/fsimage.ckpt_0000000000000000000ofsize196bytessavedin0seconds.
14/02/1208:08:04INFOnamenode.NNStorageRetentionManager:Goingtoretain1imageswithtxid>=0
14/02/1208:08:04INFOutil.ExitUtil:Exitingwithstatus0
14/02/1208:08:04INFOnamenode.NameNode:SHUTDOWN_MSG:
/************************************************************
SHUTDOWN_MSG:ShuttingdownNameNodeathadoop101/192.168.80.101
************************************************************/
[root@hadoop101hadoop]#
验证：
[root@hadoop101hadoop]#lstmp/
dfsjournal
[root@hadoop101hadoop]#lstmp/dfs/
name
【格式化NameNode会在磁盘产生一个目录，用于保存NameNode的fsimage、edits等文件】
6.启动c1中刚才格式化的NameNode
在hadoop101上执行命令：/usr/local/hadoop/sbin/hadoop-daemon.shstartnamenode
命令输出：
[root@hadoop101hadoop]#/usr/local/hadoop/sbin/hadoop-daemon.shstartnamenode
startingnamenode,loggingto/usr/local/hadoop/logs/hadoop-root-namenode-hadoop101.out
验证：
[root@hadoop101hadoop]#jps
23396JournalNode
23598Jps
23558NameNode
22491QuorumPeerMain
[root@hadoop101hadoop]#
【启动后，产生一个新的java进程NameNode】
通过浏览器访问，也可以看到下图所示
 
7.把NameNode的数据从hadoop101同步到hadoop102中
在hadoop102上执行命令：/usr/local/hadoop/bin/hdfsnamenode–bootstrapStandby
命令输出：
[root@hadoop102hadoop]#/usr/local/hadoop/bin/hdfsnamenode-bootstrapStandby
14/02/1208:17:44INFOnamenode.NameNode:STARTUP_MSG:
/************************************************************
STARTUP_MSG:StartingNameNode
STARTUP_MSG:host=hadoop102/192.168.80.102
STARTUP_MSG:args=[-bootstrapStandby]
STARTUP_MSG:version=2.2.0
STARTUP_MSG:classpath=/usr/local/hadoop/etc/hadoop:/usr/local/hadoop/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop/share/hadoop/common/lib/jsch-0.1.42.jar:/usr/local/hadoop/share/hadoop/common/lib/jersey-server-1.9.jar:/usr/local/hadoop/share/hadoop/common/lib/slf4j-log4j12-1.7.5.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-digester-1.8.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-cli-1.2.jar:/usr/local/hadoop/share/hadoop/common/lib/jackson-core-asl-1.8.8.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-el-1.0.jar:/usr/local/hadoop/share/hadoop/common/lib/jets3t-0.6.1.jar:/usr/local/hadoop/share/hadoop/common/lib/jersey-core-1.9.jar:/usr/local/hadoop/share/hadoop/common/lib/slf4j-api-1.7.5.jar:/usr/local/hadoop/share/hadoop/common/lib/xz-1.0.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-lang-2.5.jar:/usr/local/hadoop/share/hadoop/common/lib/jasper-runtime-5.5.23.jar:/usr/local/hadoop/share/hadoop/common/lib/jackson-xc-1.8.8.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-codec-1.4.jar:/usr/local/hadoop/share/hadoop/common/lib/activation-1.1.jar:/usr/local/hadoop/share/hadoop/common/lib/avro-1.7.4.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-httpclient-3.1.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/usr/local/hadoop/share/hadoop/common/lib/hadoop-annotations-2.2.0.jar:/usr/local/hadoop/share/hadoop/common/lib/jsp-api-2.1.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-compress-1.4.1.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-configuration-1.6.jar:/usr/local/hadoop/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop/share/hadoop/common/lib/zookeeper-3.4.5.jar:/usr/local/hadoop/share/hadoop/common/lib/hadoop-auth-2.2.0.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-io-2.1.jar:/usr/local/hadoop/share/hadoop/common/lib/netty-3.6.2.Final.jar:/usr/local/hadoop/share/hadoop/common/lib/stax-api-1.0.1.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-collections-3.2.1.jar:/usr/local/hadoop/share/hadoop/common/lib/servlet-api-2.5.jar:/usr/local/hadoop/share/hadoop/common/lib/junit-4.8.2.jar:/usr/local/hadoop/share/hadoop/common/lib/jetty-util-6.1.26.jar:/usr/local/hadoop/share/hadoop/common/lib/jackson-mapper-asl-1.8.8.jar:/usr/local/hadoop/share/hadoop/common/lib/jsr305-1.3.9.jar:/usr/local/hadoop/share/hadoop/common/lib/mockito-all-1.8.5.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-logging-1.1.1.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-math-2.1.jar:/usr/local/hadoop/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop/share/hadoop/common/lib/jersey-json-1.9.jar:/usr/local/hadoop/share/hadoop/common/lib/asm-3.2.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-net-3.1.jar:/usr/local/hadoop/share/hadoop/common/lib/jetty-6.1.26.jar:/usr/local/hadoop/share/hadoop/common/lib/jasper-compiler-5.5.23.jar:/usr/local/hadoop/share/hadoop/common/lib/guava-11.0.2.jar:/usr/local/hadoop/share/hadoop/common/lib/xmlenc-0.52.jar:/usr/local/hadoop/share/hadoop/common/lib/log4j-1.2.17.jar:/usr/local/hadoop/share/hadoop/common/lib/paranamer-2.3.jar:/usr/local/hadoop/share/hadoop/common/lib/jackson-jaxrs-1.8.8.jar:/usr/local/hadoop/share/hadoop/common/lib/jettison-1.1.jar:/usr/local/hadoop/share/hadoop/common/hadoop-common-2.2.0-tests.jar:/usr/local/hadoop/share/hadoop/common/hadoop-common-2.2.0.jar:/usr/local/hadoop/share/hadoop/common/hadoop-nfs-2.2.0.jar:/usr/local/hadoop/share/hadoop/hdfs:/usr/local/hadoop/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jackson-core-asl-1.8.8.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-el-1.0.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-lang-2.5.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jasper-runtime-5.5.23.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jsp-api-2.1.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-io-2.1.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jackson-mapper-asl-1.8.8.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jsr305-1.3.9.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-logging-1.1.1.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/asm-3.2.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/guava-11.0.2.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/usr/local/hadoop/share/hadoop/hdfs/hadoop-hdfs-nfs-2.2.0.jar:/usr/local/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.2.0-tests.jar:/usr/local/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.2.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jersey-server-1.9.jar:/usr/local/hadoop/share/hadoop/yarn/lib/guice-3.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jackson-core-asl-1.8.8.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jersey-core-1.9.jar:/usr/local/hadoop/share/hadoop/yarn/lib/xz-1.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/hamcrest-core-1.1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/avro-1.7.4.jar:/usr/local/hadoop/share/hadoop/yarn/lib/aopalliance-1.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/hadoop-annotations-2.2.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/javax.inject-1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-io-2.1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jackson-mapper-asl-1.8.8.jar:/usr/local/hadoop/share/hadoop/yarn/lib/asm-3.2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/junit-4.10.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/usr/local/hadoop/share/hadoop/yarn/lib/log4j-1.2.17.jar:/usr/local/hadoop/share/hadoop/yarn/lib/paranamer-2.3.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-api-2.2.0.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-tests-2.2.0.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-site-2.2.0.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-client-2.2.0.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.2.0.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.2.0.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.2.0.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.2.0.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.2.0.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-common-2.2.0.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-common-2.2.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/guice-3.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/jackson-core-asl-1.8.8.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/xz-1.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/hamcrest-core-1.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/hadoop-annotations-2.2.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/javax.inject-1.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/commons-io-2.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.8.8.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/asm-3.2.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/junit-4.10.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.2.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.2.0-tests.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.2.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.2.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.2.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.2.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.2.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.2.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.2.0.jar:/usr/local/hadoop/contrib/capacity-scheduler/*.jar
STARTUP_MSG:build=Unknown-rUnknown;compiledby'root'on2013-12-26T08:50Z
STARTUP_MSG:java=1.7.0_45
************************************************************/
14/02/1208:17:44INFOnamenode.NameNode:registeredUNIXsignalhandlersfor[TERM,HUP,INT]
=====================================================
AbouttobootstrapStandbyIDhadoop102from:
NameserviceID:cluster1
OtherNamenodeID:hadoop101
OtherNN'sHTTPaddress:hadoop101:50070
OtherNN'sIPCaddress:hadoop101/192.168.80.101:9000
NamespaceID:1496717450
BlockpoolID:BP-2022554027-192.168.80.101-1392164061887
ClusterID:c1
Layoutversion:-47
=====================================================
14/02/1208:17:48INFOcommon.Storage:Storagedirectory/usr/local/hadoop/tmp/dfs/namehasbeensuccessfullyformatted.
14/02/1208:17:48INFOnamenode.TransferFsImage:Openingconnectiontohttp://hadoop101:50070/getimage?getimage=1&txid=0&storageInfo=-47:1496717450:0:c1
14/02/1208:17:48INFOnamenode.TransferFsImage:Transfertook0.18sat0.00KB/s
14/02/1208:17:48INFOnamenode.TransferFsImage:Downloadedfilefsimage.ckpt_0000000000000000000size196bytes.
14/02/1208:17:48INFOutil.ExitUtil:Exitingwithstatus0
14/02/1208:17:48INFOnamenode.NameNode:SHUTDOWN_MSG:
/************************************************************
SHUTDOWN_MSG:ShuttingdownNameNodeathadoop102/192.168.80.102
************************************************************/
[root@hadoop102hadoop]#
验证：
[root@hadoop102hadoop]#lstmp/
dfsjournal
[root@hadoop102hadoop]#lstmp/dfs/
name
[root@hadoop102hadoop]#
【在tmp目录下产生一个目录name】
8.启动c1中另一个Namenode
在hadoop102上执行命令：/usr/local/hadoop/sbin/hadoop-daemon.shstartnamenode
命令输出：
[root@hadoop102hadoop]#/usr/local/hadoop/sbin/hadoop-daemon.shstartnamenode
startingnamenode,loggingto/usr/local/hadoop/logs/hadoop-root-namenode-hadoop102.out
验证：
[root@hadoop102hadoop]#jps
12355JournalNode
12611Jps
12573NameNode
12081QuorumPeerMain
[root@hadoop102hadoop]#
【产生java进程NameNode】
通过浏览器访问，也可以看到下图所示
 
9.格式化集群c2的一个NameNode
从hadoop103和hadoop104中任选一个即可，这里选择的是hadoop103
在hadoop103执行以下命令：/usr/local/hadoop/bin/hdfsnamenode-format-clusterIdc2
命令输出：
[root@hadoop103hadoop]#/usr/local/hadoop/bin/hdfsnamenode-format-clusterIdc2
14/02/1208:23:28INFOnamenode.NameNode:STARTUP_MSG:
/************************************************************
STARTUP_MSG:StartingNameNode
STARTUP_MSG:host=hadoop103/192.168.80.103
STARTUP_MSG:args=[-format,-clusterId,c2]
STARTUP_MSG:version=2.2.0
STARTUP_MSG:classpath=/usr/local/hadoop/etc/hadoop:/usr/local/hadoop/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop/share/hadoop/common/lib/jsch-0.1.42.jar:/usr/local/hadoop/share/hadoop/common/lib/jersey-server-1.9.jar:/usr/local/hadoop/share/hadoop/common/lib/slf4j-log4j12-1.7.5.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-digester-1.8.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-cli-1.2.jar:/usr/local/hadoop/share/hadoop/common/lib/jackson-core-asl-1.8.8.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-el-1.0.jar:/usr/local/hadoop/share/hadoop/common/lib/jets3t-0.6.1.jar:/usr/local/hadoop/share/hadoop/common/lib/jersey-core-1.9.jar:/usr/local/hadoop/share/hadoop/common/lib/slf4j-api-1.7.5.jar:/usr/local/hadoop/share/hadoop/common/lib/xz-1.0.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-lang-2.5.jar:/usr/local/hadoop/share/hadoop/common/lib/jasper-runtime-5.5.23.jar:/usr/local/hadoop/share/hadoop/common/lib/jackson-xc-1.8.8.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-codec-1.4.jar:/usr/local/hadoop/share/hadoop/common/lib/activation-1.1.jar:/usr/local/hadoop/share/hadoop/common/lib/avro-1.7.4.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-httpclient-3.1.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/usr/local/hadoop/share/hadoop/common/lib/hadoop-annotations-2.2.0.jar:/usr/local/hadoop/share/hadoop/common/lib/jsp-api-2.1.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-compress-1.4.1.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-configuration-1.6.jar:/usr/local/hadoop/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop/share/hadoop/common/lib/zookeeper-3.4.5.jar:/usr/local/hadoop/share/hadoop/common/lib/hadoop-auth-2.2.0.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-io-2.1.jar:/usr/local/hadoop/share/hadoop/common/lib/netty-3.6.2.Final.jar:/usr/local/hadoop/share/hadoop/common/lib/stax-api-1.0.1.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-collections-3.2.1.jar:/usr/local/hadoop/share/hadoop/common/lib/servlet-api-2.5.jar:/usr/local/hadoop/share/hadoop/common/lib/junit-4.8.2.jar:/usr/local/hadoop/share/hadoop/common/lib/jetty-util-6.1.26.jar:/usr/local/hadoop/share/hadoop/common/lib/jackson-mapper-asl-1.8.8.jar:/usr/local/hadoop/share/hadoop/common/lib/jsr305-1.3.9.jar:/usr/local/hadoop/share/hadoop/common/lib/mockito-all-1.8.5.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-logging-1.1.1.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-math-2.1.jar:/usr/local/hadoop/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop/share/hadoop/common/lib/jersey-json-1.9.jar:/usr/local/hadoop/share/hadoop/common/lib/asm-3.2.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-net-3.1.jar:/usr/local/hadoop/share/hadoop/common/lib/jetty-6.1.26.jar:/usr/local/hadoop/share/hadoop/common/lib/jasper-compiler-5.5.23.jar:/usr/local/hadoop/share/hadoop/common/lib/guava-11.0.2.jar:/usr/local/hadoop/share/hadoop/common/lib/xmlenc-0.52.jar:/usr/local/hadoop/share/hadoop/common/lib/log4j-1.2.17.jar:/usr/local/hadoop/share/hadoop/common/lib/paranamer-2.3.jar:/usr/local/hadoop/share/hadoop/common/lib/jackson-jaxrs-1.8.8.jar:/usr/local/hadoop/share/hadoop/common/lib/jettison-1.1.jar:/usr/local/hadoop/share/hadoop/common/hadoop-common-2.2.0-tests.jar:/usr/local/hadoop/share/hadoop/common/hadoop-common-2.2.0.jar:/usr/local/hadoop/share/hadoop/common/hadoop-nfs-2.2.0.jar:/usr/local/hadoop/share/hadoop/hdfs:/usr/local/hadoop/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jackson-core-asl-1.8.8.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-el-1.0.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-lang-2.5.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jasper-runtime-5.5.23.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jsp-api-2.1.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-io-2.1.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jackson-mapper-asl-1.8.8.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jsr305-1.3.9.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-logging-1.1.1.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/asm-3.2.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/guava-11.0.2.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/usr/local/hadoop/share/hadoop/hdfs/hadoop-hdfs-nfs-2.2.0.jar:/usr/local/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.2.0-tests.jar:/usr/local/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.2.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jersey-server-1.9.jar:/usr/local/hadoop/share/hadoop/yarn/lib/guice-3.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jackson-core-asl-1.8.8.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jersey-core-1.9.jar:/usr/local/hadoop/share/hadoop/yarn/lib/xz-1.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/hamcrest-core-1.1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/avro-1.7.4.jar:/usr/local/hadoop/share/hadoop/yarn/lib/aopalliance-1.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/hadoop-annotations-2.2.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/javax.inject-1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-io-2.1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jackson-mapper-asl-1.8.8.jar:/usr/local/hadoop/share/hadoop/yarn/lib/asm-3.2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/junit-4.10.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/usr/local/hadoop/share/hadoop/yarn/lib/log4j-1.2.17.jar:/usr/local/hadoop/share/hadoop/yarn/lib/paranamer-2.3.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-api-2.2.0.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-tests-2.2.0.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-site-2.2.0.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-client-2.2.0.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.2.0.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.2.0.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.2.0.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.2.0.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.2.0.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-common-2.2.0.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-common-2.2.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/guice-3.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/jackson-core-asl-1.8.8.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/xz-1.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/hamcrest-core-1.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/hadoop-annotations-2.2.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/javax.inject-1.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/commons-io-2.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.8.8.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/asm-3.2.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/junit-4.10.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.2.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.2.0-tests.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.2.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.2.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.2.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.2.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.2.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.2.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.2.0.jar:/usr/local/hadoop/contrib/capacity-scheduler/*.jar
STARTUP_MSG:build=Unknown-rUnknown;compiledby'root'on2013-12-26T08:50Z
STARTUP_MSG:java=1.7.0_45
************************************************************/
14/02/1208:23:28INFOnamenode.NameNode:registeredUNIXsignalhandlersfor[TERM,HUP,INT]
14/02/1208:23:30WARNutil.NativeCodeLoader:Unabletoloadnative-hadooplibraryforyourplatform...usingbuiltin-javaclasseswhereapplicable
Formattingusingclusterid:c2
14/02/1208:23:31INFOnamenode.HostFileManager:readincludes:
HostSet(
)
14/02/1208:23:31INFOnamenode.HostFileManager:readexcludes:
HostSet(
)
14/02/1208:23:31INFOblockmanagement.DatanodeManager:dfs.block.invalidate.limit=1000
14/02/1208:23:31INFOutil.GSet:ComputingcapacityformapBlocksMap
14/02/1208:23:31INFOutil.GSet:VMtype=64-bit
14/02/1208:23:31INFOutil.GSet:2.0%maxmemory=966.7MB
14/02/1208:23:31INFOutil.GSet:capacity=2^21=2097152entries
14/02/1208:23:31INFOblockmanagement.BlockManager:dfs.block.access.token.enable=false
14/02/1208:23:31INFOblockmanagement.BlockManager:defaultReplication=2
14/02/1208:23:31INFOblockmanagement.BlockManager:maxReplication=512
14/02/1208:23:31INFOblockmanagement.BlockManager:minReplication=1
14/02/1208:23:31INFOblockmanagement.BlockManager:maxReplicationStreams=2
14/02/1208:23:31INFOblockmanagement.BlockManager:shouldCheckForEnoughRacks=false
14/02/1208:23:31INFOblockmanagement.BlockManager:replicationRecheckInterval=3000
14/02/1208:23:31INFOblockmanagement.BlockManager:encryptDataTransfer=false
14/02/1208:23:31INFOnamenode.FSNamesystem:fsOwner=root(auth:SIMPLE)
14/02/1208:23:31INFOnamenode.FSNamesystem:supergroup=supergroup
14/02/1208:23:31INFOnamenode.FSNamesystem:isPermissionEnabled=true
14/02/1208:23:31INFOnamenode.FSNamesystem:DeterminednameserviceID:cluster2
14/02/1208:23:31INFOnamenode.FSNamesystem:HAEnabled:true
14/02/1208:23:31INFOnamenode.FSNamesystem:AppendEnabled:true
14/02/1208:23:31INFOutil.GSet:ComputingcapacityformapINodeMap
14/02/1208:23:31INFOutil.GSet:VMtype=64-bit
14/02/1208:23:31INFOutil.GSet:1.0%maxmemory=966.7MB
14/02/1208:23:31INFOutil.GSet:capacity=2^20=1048576entries
14/02/1208:23:31INFOnamenode.NameNode:Cachingfilenamesoccuringmorethan10times
14/02/1208:23:31INFOnamenode.FSNamesystem:dfs.namenode.safemode.threshold-pct=0.9990000128746033
14/02/1208:23:31INFOnamenode.FSNamesystem:dfs.namenode.safemode.min.datanodes=0
14/02/1208:23:31INFOnamenode.FSNamesystem:dfs.namenode.safemode.extension=30000
14/02/1208:23:31INFOnamenode.FSNamesystem:Retrycacheonnamenodeisenabled
14/02/1208:23:31INFOnamenode.FSNamesystem:Retrycachewilluse0.03oftotalheapandretrycacheentryexpirytimeis600000millis
14/02/1208:23:31INFOutil.GSet:ComputingcapacityformapNamenodeRetryCache
14/02/1208:23:31INFOutil.GSet:VMtype=64-bit
14/02/1208:23:31INFOutil.GSet:0.029999999329447746%maxmemory=966.7MB
14/02/1208:23:31INFOutil.GSet:capacity=2^15=32768entries
14/02/1208:23:33INFOcommon.Storage:Storagedirectory/usr/local/hadoop/tmp/dfs/namehasbeensuccessfullyformatted.
14/02/1208:23:33INFOnamenode.FSImage:Savingimagefile/usr/local/hadoop/tmp/dfs/name/current/fsimage.ckpt_0000000000000000000usingnocompression
14/02/1208:23:33INFOnamenode.FSImage:Imagefile/usr/local/hadoop/tmp/dfs/name/current/fsimage.ckpt_0000000000000000000ofsize196bytessavedin0seconds.
14/02/1208:23:33INFOnamenode.NNStorageRetentionManager:Goingtoretain1imageswithtxid>=0
14/02/1208:23:33INFOutil.ExitUtil:Exitingwithstatus0
14/02/1208:23:33INFOnamenode.NameNode:SHUTDOWN_MSG:
/************************************************************
SHUTDOWN_MSG:ShuttingdownNameNodeathadoop103/192.168.80.103
************************************************************/
[root@hadoop103hadoop]#
【上面的输出可以看到/usr/local/hadoop/tmp/dfs/name被成功格式化了】
验证：
[root@hadoop103hadoop]#lstmp/
dfsjournal
[root@hadoop103hadoop]#lstmp/dfs/
name
[root@hadoop103hadoop]#
10.启动c2中刚才格式化的NameNode
在hadoop103上执行命令：/usr/local/hadoop/sbin/hadoop-daemon.shstartnamenode
命令输出：
[root@hadoop103hadoop]#/usr/local/hadoop/sbin/hadoop-daemon.shstartnamenode
startingnamenode,loggingto/usr/local/hadoop/logs/hadoop-root-namenode-hadoop103.out
[root@hadoop103hadoop]#
验证：
[root@hadoop103hadoop]#jps
11290JournalNode
11560NameNode
10972QuorumPeerMain
11600Jps
[root@hadoop103hadoop]#
也可以通过浏览器访问http://hadoop103:50070，可以看到如上图页面，此处省略截图。
11.把NameNode的数据从hadoop103同步到hadoop104中
在hadoop104上执行命令：/usr/local/hadoop/bin/hdfsnamenode–bootstrapStandby
命令输出：
[root@hadoop104hadoop]#/usr/local/hadoop/bin/hdfsnamenode-bootstrapStandby
14/02/1208:28:30INFOnamenode.NameNode:STARTUP_MSG:
/************************************************************
STARTUP_MSG:StartingNameNode
STARTUP_MSG:host=hadoop104/192.168.80.104
STARTUP_MSG:args=[-bootstrapStandby]
STARTUP_MSG:version=2.2.0
STARTUP_MSG:classpath=/usr/local/hadoop/etc/hadoop:/usr/local/hadoop/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop/share/hadoop/common/lib/jsch-0.1.42.jar:/usr/local/hadoop/share/hadoop/common/lib/jersey-server-1.9.jar:/usr/local/hadoop/share/hadoop/common/lib/slf4j-log4j12-1.7.5.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-digester-1.8.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-cli-1.2.jar:/usr/local/hadoop/share/hadoop/common/lib/jackson-core-asl-1.8.8.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-el-1.0.jar:/usr/local/hadoop/share/hadoop/common/lib/jets3t-0.6.1.jar:/usr/local/hadoop/share/hadoop/common/lib/jersey-core-1.9.jar:/usr/local/hadoop/share/hadoop/common/lib/slf4j-api-1.7.5.jar:/usr/local/hadoop/share/hadoop/common/lib/xz-1.0.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-lang-2.5.jar:/usr/local/hadoop/share/hadoop/common/lib/jasper-runtime-5.5.23.jar:/usr/local/hadoop/share/hadoop/common/lib/jackson-xc-1.8.8.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-codec-1.4.jar:/usr/local/hadoop/share/hadoop/common/lib/activation-1.1.jar:/usr/local/hadoop/share/hadoop/common/lib/avro-1.7.4.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-httpclient-3.1.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/usr/local/hadoop/share/hadoop/common/lib/hadoop-annotations-2.2.0.jar:/usr/local/hadoop/share/hadoop/common/lib/jsp-api-2.1.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-compress-1.4.1.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-configuration-1.6.jar:/usr/local/hadoop/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop/share/hadoop/common/lib/zookeeper-3.4.5.jar:/usr/local/hadoop/share/hadoop/common/lib/hadoop-auth-2.2.0.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-io-2.1.jar:/usr/local/hadoop/share/hadoop/common/lib/netty-3.6.2.Final.jar:/usr/local/hadoop/share/hadoop/common/lib/stax-api-1.0.1.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-collections-3.2.1.jar:/usr/local/hadoop/share/hadoop/common/lib/servlet-api-2.5.jar:/usr/local/hadoop/share/hadoop/common/lib/junit-4.8.2.jar:/usr/local/hadoop/share/hadoop/common/lib/jetty-util-6.1.26.jar:/usr/local/hadoop/share/hadoop/common/lib/jackson-mapper-asl-1.8.8.jar:/usr/local/hadoop/share/hadoop/common/lib/jsr305-1.3.9.jar:/usr/local/hadoop/share/hadoop/common/lib/mockito-all-1.8.5.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-logging-1.1.1.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-math-2.1.jar:/usr/local/hadoop/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop/share/hadoop/common/lib/jersey-json-1.9.jar:/usr/local/hadoop/share/hadoop/common/lib/asm-3.2.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-net-3.1.jar:/usr/local/hadoop/share/hadoop/common/lib/jetty-6.1.26.jar:/usr/local/hadoop/share/hadoop/common/lib/jasper-compiler-5.5.23.jar:/usr/local/hadoop/share/hadoop/common/lib/guava-11.0.2.jar:/usr/local/hadoop/share/hadoop/common/lib/xmlenc-0.52.jar:/usr/local/hadoop/share/hadoop/common/lib/log4j-1.2.17.jar:/usr/local/hadoop/share/hadoop/common/lib/paranamer-2.3.jar:/usr/local/hadoop/share/hadoop/common/lib/jackson-jaxrs-1.8.8.jar:/usr/local/hadoop/share/hadoop/common/lib/jettison-1.1.jar:/usr/local/hadoop/share/hadoop/common/hadoop-common-2.2.0-tests.jar:/usr/local/hadoop/share/hadoop/common/hadoop-common-2.2.0.jar:/usr/local/hadoop/share/hadoop/common/hadoop-nfs-2.2.0.jar:/usr/local/hadoop/share/hadoop/hdfs:/usr/local/hadoop/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jackson-core-asl-1.8.8.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-el-1.0.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-lang-2.5.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jasper-runtime-5.5.23.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jsp-api-2.1.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-io-2.1.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jackson-mapper-asl-1.8.8.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jsr305-1.3.9.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-logging-1.1.1.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/asm-3.2.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/guava-11.0.2.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/usr/local/hadoop/share/hadoop/hdfs/hadoop-hdfs-nfs-2.2.0.jar:/usr/local/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.2.0-tests.jar:/usr/local/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.2.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jersey-server-1.9.jar:/usr/local/hadoop/share/hadoop/yarn/lib/guice-3.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jackson-core-asl-1.8.8.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jersey-core-1.9.jar:/usr/local/hadoop/share/hadoop/yarn/lib/xz-1.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/hamcrest-core-1.1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/avro-1.7.4.jar:/usr/local/hadoop/share/hadoop/yarn/lib/aopalliance-1.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/hadoop-annotations-2.2.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/javax.inject-1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-io-2.1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jackson-mapper-asl-1.8.8.jar:/usr/local/hadoop/share/hadoop/yarn/lib/asm-3.2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/junit-4.10.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/usr/local/hadoop/share/hadoop/yarn/lib/log4j-1.2.17.jar:/usr/local/hadoop/share/hadoop/yarn/lib/paranamer-2.3.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-api-2.2.0.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-tests-2.2.0.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-site-2.2.0.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-client-2.2.0.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.2.0.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.2.0.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.2.0.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.2.0.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.2.0.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-common-2.2.0.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-common-2.2.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/guice-3.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/jackson-core-asl-1.8.8.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/xz-1.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/hamcrest-core-1.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/hadoop-annotations-2.2.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/javax.inject-1.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/commons-io-2.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.8.8.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/asm-3.2.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/junit-4.10.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.2.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.2.0-tests.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.2.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.2.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.2.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.2.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.2.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.2.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.2.0.jar:/usr/local/hadoop/contrib/capacity-scheduler/*.jar
STARTUP_MSG:build=Unknown-rUnknown;compiledby'root'on2013-12-26T08:50Z
STARTUP_MSG:java=1.7.0_45
************************************************************/
14/02/1208:28:35INFOnamenode.NameNode:registeredUNIXsignalhandlersfor[TERM,HUP,INT]
=====================================================
AbouttobootstrapStandbyIDhadoop104from:
NameserviceID:cluster2
OtherNamenodeID:hadoop103
OtherNN'sHTTPaddress:hadoop103:50070
OtherNN'sIPCaddress:hadoop103/192.168.80.103:9000
NamespaceID:698609742
BlockpoolID:BP-1304582337-192.168.80.103-1392164613254
ClusterID:c2
Layoutversion:-47
=====================================================
14/02/1208:28:39INFOcommon.Storage:Storagedirectory/usr/local/hadoop/tmp/dfs/namehasbeensuccessfullyformatted.
14/02/1208:28:39INFOnamenode.TransferFsImage:Openingconnectiontohttp://hadoop103:50070/getimage?getimage=1&txid=0&storageInfo=-47:698609742:0:c2
14/02/1208:28:40INFOnamenode.TransferFsImage:Transfertook0.67sat0.00KB/s
14/02/1208:28:40INFOnamenode.TransferFsImage:Downloadedfilefsimage.ckpt_0000000000000000000size196bytes.
14/02/1208:28:40INFOutil.ExitUtil:Exitingwithstatus0
14/02/1208:28:40INFOnamenode.NameNode:SHUTDOWN_MSG:
/************************************************************
SHUTDOWN_MSG:ShuttingdownNameNodeathadoop104/192.168.80.104
************************************************************/
验证：
[root@hadoop104hadoop]#pwd
/usr/local/hadoop
[root@hadoop104hadoop]#lstmp/
dfs
[root@hadoop104hadoop]#lstmp/dfs/
name
[root@hadoop104hadoop]#
12.启动c2中另一个Namenode
在hadoop104上执行命令：/usr/local/hadoop/sbin/hadoop-daemon.shstartnamenode
命令输出：
[root@hadoop104hadoop]#/usr/local/hadoop/sbin/hadoop-daemon.shstartnamenode
startingnamenode,loggingto/usr/local/hadoop/logs/hadoop-root-namenode-hadoop104.out
[root@hadoop104hadoop]#
验证：
[root@hadoop104hadoop]#jps
8822NameNode
8975Jps
[root@hadoop104hadoop]#
也可以通过浏览器访问http://hadoop104:50070，可以看到如上图页面，此处省略截图。
13.启动所有的DataNode
在hadoop101上执行命令：/usr/local/hadoop/sbin/hadoop-daemons.shstartdatanode
命令输出：
[root@hadoop101hadoop]#/usr/local/hadoop/sbin/hadoop-daemons.shstartdatanode
hadoop101:startingdatanode,loggingto/usr/local/hadoop/logs/hadoop-root-datanode-hadoop101.out
hadoop103:startingdatanode,loggingto/usr/local/hadoop/logs/hadoop-root-datanode-hadoop103.out
hadoop102:startingdatanode,loggingto/usr/local/hadoop/logs/hadoop-root-datanode-hadoop102.out
hadoop104:startingdatanode,loggingto/usr/local/hadoop/logs/hadoop-root-datanode-hadoop104.out
[root@hadoop101hadoop]#
【上述命令会在四个节点分别启动DataNode进程】
验证（以hadoop101为例）：
[root@hadoop101hadoop]#jps
23396JournalNode
24302Jps
24232DataNode
23558NameNode
22491QuorumPeerMain
[root@hadoop101hadoop]#
【可以看到java进程DataNode】
14.启动Yarn
在hadoop101上执行命令：/usr/local/hadoop/sbin/start-yarn.sh
命令输出：
[root@hadoop101hadoop]#/usr/local/hadoop/sbin/start-yarn.sh
startingyarndaemons
startingresourcemanager,loggingto/usr/local/hadoop/logs/yarn-root-resourcemanager-hadoop101.out
hadoop104:startingnodemanager,loggingto/usr/local/hadoop/logs/yarn-root-nodemanager-hadoop104.out
hadoop103:startingnodemanager,loggingto/usr/local/hadoop/logs/yarn-root-nodemanager-hadoop103.out
hadoop102:startingnodemanager,loggingto/usr/local/hadoop/logs/yarn-root-nodemanager-hadoop102.out
hadoop101:startingnodemanager,loggingto/usr/local/hadoop/logs/yarn-root-nodemanager-hadoop101.out
[root@hadoop101hadoop]#
验证：
[root@hadoop101hadoop]#jps
23396JournalNode
25154ResourceManager
25247NodeManager
24232DataNode
23558NameNode
22491QuorumPeerMain
25281Jps
[root@hadoop101hadoop]#
【产生java进程ResourceManager和NodeManager】
也可以通过浏览器访问，如下图
 
15.启动ZooKeeperFailoverController
在hadoop101、hadoop102、hadoop103、hadoop104上分别执行命令：/usr/local/hadoop/sbin/hadoop-daemon.shstartzkfc
命令输出（以hadoop101为例）：
[root@hadoop101hadoop]#/usr/local/hadoop/sbin/hadoop-daemon.shstartzkfc
startingzkfc,loggingto/usr/local/hadoop/logs/hadoop-root-zkfc-hadoop101.out
[root@hadoop101hadoop]#
验证（以hadoop101为例）：
[root@hadoop101hadoop]#jps
24599DFSZKFailoverController
23396JournalNode
24232DataNode
23558NameNode
22491QuorumPeerMain
24654Jps
[root@hadoop101hadoop]#
【产生java进程DFSZKFailoverController】
16.验证HDFS是否好用
在任意一个节点上执行以下命令（这里以hadoop101为例），把数据上传到HDFS集群中
[root@hadoop101hadoop]#pwd
/usr/local/hadoop/etc/hadoop
[root@hadoop101hadoop]#ls
capacity-scheduler.xmlhadoop-metrics.propertieshttpfs-site.xmlssl-server.xml.example
configuration.xslhadoop-policy.xmllog4j.propertiesstartall.sh
container-executor.cfghdfs2-site.xmlmapred-env.shyarn-env.sh
core-site.xmlhdfs-site.xmlmapred-queues.xml.templateyarn-site.xml
fairscheduler.xmlhttpfs-env.shmapred-site.xmlzookeeper.out
hadoop-env.shhttpfs-log4j.propertiesslaves
hadoop-metrics2.propertieshttpfs-signature.secretssl-client.xml.example
[root@hadoop101hadoop]#hadoopfs-putcore-site.xml/
【上传到集群中，默认是上传到HDFS联盟的c1集群中】
验证：
[root@hadoop101hadoop]#hadoopfs-ls/
Found1items
-rw-r--r--2rootsupergroup4462014-02-1209:00/core-site.xml
[root@hadoop101hadoop]#
也可以通过浏览器查看，数据默认是放在第一个集群中的
 
17.验证Yarn是否好用
在hadoop101上执行以下命令hadoopjar/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.2.0.jarwordcount/core-site.xml/out
命令输出：
[root@hadoop101hadoop]#hadoopjar/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.2.0.jarwordcount/core-site.xml/out
14/02/1211:43:55INFOclient.RMProxy:ConnectingtoResourceManagerathadoop101/192.168.80.101:8032
14/02/1211:43:59INFOinput.FileInputFormat:Totalinputpathstoprocess:1
14/02/1211:43:59INFOmapreduce.JobSubmitter:numberofsplits:1
14/02/1211:43:59INFOConfiguration.deprecation:user.nameisdeprecated.Instead,usemapreduce.job.user.name
14/02/1211:43:59INFOConfiguration.deprecation:mapred.jarisdeprecated.Instead,usemapreduce.job.jar
14/02/1211:43:59INFOConfiguration.deprecation:mapred.output.value.classisdeprecated.Instead,usemapreduce.job.output.value.class
14/02/1211:43:59INFOConfiguration.deprecation:mapreduce.combine.classisdeprecated.Instead,usemapreduce.job.combine.class
14/02/1211:43:59INFOConfiguration.deprecation:mapreduce.map.classisdeprecated.Instead,usemapreduce.job.map.class
14/02/1211:43:59INFOConfiguration.deprecation:mapred.job.nameisdeprecated.Instead,usemapreduce.job.name
14/02/1211:43:59INFOConfiguration.deprecation:mapreduce.reduce.classisdeprecated.Instead,usemapreduce.job.reduce.class
14/02/1211:43:59INFOConfiguration.deprecation:mapred.input.dirisdeprecated.Instead,usemapreduce.input.fileinputformat.inputdir
14/02/1211:43:59INFOConfiguration.deprecation:mapred.output.dirisdeprecated.Instead,usemapreduce.output.fileoutputformat.outputdir
14/02/1211:43:59INFOConfiguration.deprecation:mapred.map.tasksisdeprecated.Instead,usemapreduce.job.maps
14/02/1211:43:59INFOConfiguration.deprecation:mapred.output.key.classisdeprecated.Instead,usemapreduce.job.output.key.class
14/02/1211:43:59INFOConfiguration.deprecation:mapred.working.dirisdeprecated.Instead,usemapreduce.job.working.dir
14/02/1211:44:01INFOmapreduce.JobSubmitter:Submittingtokensforjob:job_1392169506119_0002
14/02/1211:44:04INFOimpl.YarnClientImpl:Submittedapplicationapplication_1392169506119_0002toResourceManagerathadoop101/192.168.80.101:8032
14/02/1211:44:05INFOmapreduce.Job:Theurltotrackthejob:http://hadoop101:8088/proxy/application_1392169506119_0002/
14/02/1211:44:05INFOmapreduce.Job:Runningjob:job_1392169506119_0002
14/02/1211:44:41INFOmapreduce.Job:Jobjob_1392169506119_0002runninginubermode:false
14/02/1211:44:41INFOmapreduce.Job:map0%reduce0%
14/02/1211:45:37INFOmapreduce.Job:map100%reduce0%
14/02/1211:46:54INFOmapreduce.Job:map100%reduce100%
14/02/1211:47:01INFOmapreduce.Job:Jobjob_1392169506119_0002completedsuccessfully
14/02/1211:47:02INFOmapreduce.Job:Counters:43
FileSystemCounters
FILE:Numberofbytesread=472
FILE:Numberofbyteswritten=164983
FILE:Numberofreadoperations=0
FILE:Numberoflargereadoperations=0
FILE:Numberofwriteoperations=0
HDFS:Numberofbytesread=540
HDFS:Numberofbyteswritten=402
HDFS:Numberofreadoperations=6
HDFS:Numberoflargereadoperations=0
HDFS:Numberofwriteoperations=2
JobCounters
Launchedmaptasks=1
Launchedreducetasks=1
Data-localmaptasks=1
Totaltimespentbyallmapsinoccupiedslots(ms)=63094
Totaltimespentbyallreducesinoccupiedslots(ms)=57228
Map-ReduceFramework
Mapinputrecords=17
Mapoutputrecords=20
Mapoutputbytes=496
Mapoutputmaterializedbytes=472
Inputsplitbytes=94
Combineinputrecords=20
Combineoutputrecords=16
Reduceinputgroups=16
Reduceshufflebytes=472
Reduceinputrecords=16
Reduceoutputrecords=16
SpilledRecords=32
ShuffledMaps=1
FailedShuffles=0
MergedMapoutputs=1
GCtimeelapsed(ms)=632
CPUtimespent(ms)=3010
Physicalmemory(bytes)snapshot=255528960
Virtualmemory(bytes)snapshot=1678471168
Totalcommittedheapusage(bytes)=126660608
ShuffleErrors
BAD_ID=0
CONNECTION=0
IO_ERROR=0
WRONG_LENGTH=0
WRONG_MAP=0
WRONG_REDUCE=0
FileInputFormatCounters
BytesRead=446
FileOutputFormatCounters
BytesWritten=402
[root@hadoop101hadoop]#
验证：
[root@hadoop101hadoop]#hadoopfs-ls/out
Found2items
-rw-r--r--2rootsupergroup02014-02-1211:46/out/_SUCCESS
-rw-r--r--2rootsupergroup4022014-02-1211:46/out/part-r-00000
[root@hadoop101hadoop]#hadoopfs-text/out/part-r-00000
</configuration>1
</property>3
<?xml1
<?xml-stylesheet1
<configuration>1
<name>fs.defaultFS</name>1
<name>ha.zookeeper.quorum</name>1
<name>hadoop.tmp.dir</name>1
<property>3
<value>/usr/local/hadoop/tmp</value>1
<value>hadoop101:2181,hadoop102:2181,hadoop103:2181</value>1
<value>hdfs://cluster1</value>1
encoding="UTF-8"?>1
href="configuration.xsl"?>1
type="text/xsl"1
version="1.0"1
[root@hadoop101hadoop]#
18.验证HA的故障自动转移是否好用
观察cluster1的两个NameNode的状态，hadoop101的状态是standby，hadoop102的状态是active，如下图。
 

 
下面我们杀死hadoop102的NameNode进程，观察hadoop101的状态是否会自动切换成active。
在hadoop102执行以下命令
[root@hadoop102hadoop]#jps
13389DFSZKFailoverController
12355JournalNode
13056DataNode
15660Jps
14496NodeManager
12573NameNode
12081QuorumPeerMain
[root@hadoop102hadoop]#kill-912573
[root@hadoop102hadoop]#jps
13389DFSZKFailoverController
12355JournalNode
13056DataNode
14496NodeManager
15671Jps
12081QuorumPeerMain
[root@hadoop102hadoop]#
再观察页面，发现如下图所示
 

 
证明HDFS的高可靠是可用的。

结语
以上是hadoop2.2.0的HDFS集群HA配置和自动切换、HDFSfederation配置、Yarn配置的详细过程，这绝对是国内互联网第一篇详细讲述这些配置的文章，大家可以根据以上步骤搭建。在搭建过程中，一定要注意命令的执行顺序和每一步的验证工作。
对于以上的这套安装步骤，是作者在尝试很多遍不同配置方法之后总结出来的，尽可能的减少配置参数，并对其中的各项配置参数进行了详细注释，帮助大家了解搭建原理。


